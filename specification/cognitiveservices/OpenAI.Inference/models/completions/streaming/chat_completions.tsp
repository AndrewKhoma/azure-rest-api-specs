import "@typespec/rest";
import "@typespec/http";
import "@typespec/versioning";

import "../azure_chat_extensions.tsp";
import "../common.tsp";
import "../functions.tsp";
import "../chat_completions.tsp";

using TypeSpec.Rest;
using TypeSpec.Http;
using TypeSpec.Versioning;

namespace Azure.OpenAI;

@doc("The name and arguments of a function that should be called, as generated by the model.")
@added(ServiceApiVersions.v2023_07_01_Preview)
model FunctionCallStreaming {
  @doc("The name of the function to call.")
  name?: string;

  @doc("""
  The arguments to call the function with, as generated by the model in JSON format.
  Note that the model does not always generate valid JSON, and may hallucinate parameters
  not defined by your function schema. Validate the arguments in your code before calling
  your function.
  """)
  arguments?: string;
}

// Only "id" and "function" are always present, AFAICT. The other two fields are updated on each message.
@added(ServiceApiVersions.v2023_12_01_Preview)
model ToolCallStreaming {
  index: int32;
  id?: string;
  type?: string; // only "function" for now
  function: FunctionCallStreaming;
}

@doc("A single, role-attributed message within a chat completion interaction.")
model ChatCompletionsStreamDelta {
  @doc("The role associated with this message payload.")
  @projectedName("json", "role")
  role?: ChatRole;

  #suppress "@azure-tools/typespec-azure-core/no-nullable" "we explicitly want a nullable string"
  @doc("The text associated with this message payload.")
  @projectedName("json", "content")
  content?: string;

  @doc("""
    The name of the author of this message. `name` is required if role is `function`, and it should be the name of the
    function whose response is in the `content`. May contain a-z, A-Z, 0-9, and underscores, with a maximum length of
    64 characters.
    """)
  name?: string;

  @doc("The name and arguments of a function that should be called, as generated by the model.")
  @added(ServiceApiVersions.v2023_07_01_Preview)
  @projectedName("json", "function_call")
  functionCall?: FunctionCallStreamDelta;

  @added(ServiceApiVersions.v2023_12_01_Preview)
  @projectedName("json", "tool_calls")
  toolCalls: ToolCallStreaming[];

  @doc("""
    Additional context data associated with a chat message when requesting chat completions using compatible Azure
    OpenAI chat extensions. This includes information like the intermediate data source retrievals used to service a
    request.
    This context information is only populated when using Azure OpenAI with chat extensions capabilities configured.
  """)
  @added(ServiceApiVersions.v2023_08_01_Preview)
  @projectedName("csharp", "AzureExtensionsContext")
  context?: AzureChatExtensionsMessageContext;
}

@doc("""
The representation of a single prompt completion as part of an overall chat completions request.
Generally, `n` choices are generated per provided prompt with a default value of 1.
Token limits and other settings may limit the number of choices generated.
""")
model ChatChoiceStream {
  @doc("The ordered index associated with this chat completions choice.")
  @projectedName("json", "index")
  index: int32;

  #suppress "@azure-tools/typespec-azure-core/no-nullable" "The operation already returns nulls"
  #suppress "@azure-tools/typespec-autorest/union-unsupported" "OpenAPI v2 support deferred"
  @doc("The reason that this chat completions choice completed its generated.")
  @projectedName("json", "finish_reason")
  finishReason: CompletionsFinishReason | null;

  @doc("""
  The reason the model stopped generating tokens, together with any applicable details.
  This structured representation replaces 'finish_reason' for some models.
  """)
  @added(ServiceApiVersions.v2023_12_01_Preview)
  @projectedName("json", "finish_details")
  finishDetails?: ChatFinishDetails;

  @doc("The delta message content for a streaming response.")
  @projectedName("json", "delta")
  @projectedName("csharp", "InternalStreamingDeltaMessage")
  delta: ChatCompletionsStreamDelta;

  @doc("""
    Information about the content filtering category (hate, sexual, violence, self_harm), if it
    has been detected, as well as the severity level (very_low, low, medium, high-scale that
    determines the intensity and risk level of harmful content) and if it has been filtered or not.
    """)
  @added(ServiceApiVersions.v2023_06_01_Preview)
  @projectedName("json", "content_filter_results")
  contentFilterResults?: ContentFilterResultsForChoice;
}

@doc("""
Representation of the response data from a chat completions request.
Completions support a wide variety of tasks and generate text that continues from or "completes"
provided prompt data.
""")
model ChatCompletionsStream {
  @doc("A unique identifier associated with this chat completions response.")
  @projectedName("json", "id")
  id: string;

  @doc("""
    The first timestamp associated with generation activity for this completions response,
    represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
    """)
  @projectedName("json", "created")
  @projectedName("java", "createdAt")
  @encode(DateTimeKnownEncoding.unixTimestamp, int32)
  created: utcDateTime;

  @doc("""
  Shoudl we add object?
  """)
  object: string;

  @doc("""
  model
  """)
  `model`: string;


  @doc("""
    The collection of completions choices associated with this completions response.
    Generally, `n` choices are generated per provided prompt with a default value of 1.
    Token limits and other settings may limit the number of choices generated.
    """)
  @projectedName("json", "choices")
  choices: ChatChoiceStream[];

  @doc("""
  Content filtering results for zero or more prompts in the request. In a streaming request,
  results for different prompts may arrive at different times or in different orders.
  """)
  @added(ServiceApiVersions.v2023_06_01_Preview)
  @projectedName("json", "prompt_filter_results")
  promptFilterResults?: ContentFilterResultsForPrompt[];


  @doc("""
  new field
  """)
  @projectedName("json", "system_fingerprint")
  systemFingerprint?: string;


  // TODO: this doesn't seem to be present at all.
  // @doc("""
  //   Usage information for tokens processed and generated as part of this completions operation.
  //   """)
  // @projectedName("json", "usage")
  // usage?: CompletionsUsage;
}
